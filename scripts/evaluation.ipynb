{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script creates the final evaluation CSV files and calculates the results of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import eval4ner.muc as muc\n",
    "import pprint\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done\\\\BREV_B1844-1871ht_B18700505FH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\brev_dacy_large.csv', converters={'dacy_large': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>text</th>\n",
       "      <th>dacy_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREV_B1844-1871ht_18670308FH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREV_B1844-1871ht_B18260306NTB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREV_B1844-1871ht_B18440520PL</td>\n",
       "      <td>Du maa virkelig undskylde, at jeg først nu bes...</td>\n",
       "      <td>[(PER, Hedevall), (PER, Reimann), (PER, Reiman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREV_B1844-1871ht_B18441006HSte</td>\n",
       "      <td>Tilgiv at jeg ikke før har besvaret Dit Brev, ...</td>\n",
       "      <td>[(PER, Reimann), (LOC, Byens), (PER, Mdm Reima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREV_B1844-1871ht_B18450801AWE</td>\n",
       "      <td>\\nJomfru M: Wahl hilses venskabeligst fra</td>\n",
       "      <td>[(PER, M: Wahl)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Hjerteligste</td>\n",
       "      <td>\\nHjerteligste ønsker!Tør desværre ikke selv p...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Med_udtrykket</td>\n",
       "      <td>\\n\\nMed udtrykket af min sympati for komitéens...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Tallene</td>\n",
       "      <td>\\nTallene må utvilsomt være skrevne af mig sel...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Wenn_Sie</td>\n",
       "      <td>\\n\\n\\n Wenn Sie keine andere Verwendung für Ih...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>BREV_B1890-1905ht_BudatWA</td>\n",
       "      <td>\\nHjertelig velkommen når De vil! For resten v...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2449 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        files  \\\n",
       "0                BREV_B1844-1871ht_18670308FH   \n",
       "1              BREV_B1844-1871ht_B18260306NTB   \n",
       "2               BREV_B1844-1871ht_B18440520PL   \n",
       "3             BREV_B1844-1871ht_B18441006HSte   \n",
       "4              BREV_B1844-1871ht_B18450801AWE   \n",
       "...                                       ...   \n",
       "2444   BREV_B1890-1905ht_BudatNN_Hjerteligste   \n",
       "2445  BREV_B1890-1905ht_BudatNN_Med_udtrykket   \n",
       "2446        BREV_B1890-1905ht_BudatNN_Tallene   \n",
       "2447       BREV_B1890-1905ht_BudatNN_Wenn_Sie   \n",
       "2448                BREV_B1890-1905ht_BudatWA   \n",
       "\n",
       "                                                   text  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2     Du maa virkelig undskylde, at jeg først nu bes...   \n",
       "3     Tilgiv at jeg ikke før har besvaret Dit Brev, ...   \n",
       "4             \\nJomfru M: Wahl hilses venskabeligst fra   \n",
       "...                                                 ...   \n",
       "2444  \\nHjerteligste ønsker!Tør desværre ikke selv p...   \n",
       "2445  \\n\\nMed udtrykket af min sympati for komitéens...   \n",
       "2446  \\nTallene må utvilsomt være skrevne af mig sel...   \n",
       "2447  \\n\\n\\n Wenn Sie keine andere Verwendung für Ih...   \n",
       "2448  \\nHjertelig velkommen når De vil! For resten v...   \n",
       "\n",
       "                                             dacy_large  \n",
       "0                                                    []  \n",
       "1                                                    []  \n",
       "2     [(PER, Hedevall), (PER, Reimann), (PER, Reiman...  \n",
       "3     [(PER, Reimann), (LOC, Byens), (PER, Mdm Reima...  \n",
       "4                                      [(PER, M: Wahl)]  \n",
       "...                                                 ...  \n",
       "2444                                                 []  \n",
       "2445                                                 []  \n",
       "2446                                                 []  \n",
       "2447                                                 []  \n",
       "2448                                                 []  \n",
       "\n",
       "[2449 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done' # all\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done\\\\1844-1871'\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done\\\\1871-1879'\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done\\\\1880-1889'\n",
    "path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done\\\\1890-1905'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "my_annotation = []\n",
    "their_annotation = []\n",
    "num_words = []\n",
    "x = []\n",
    "text_count = []\n",
    "\n",
    "for filename in all_files:\n",
    "    text_filename = filename\n",
    "    df = pd.read_csv(filename, dtype = {'who': str, 'anno': str})\n",
    "    \n",
    "    for i,r in df.iterrows():\n",
    "        anno = r['human_annotation']\n",
    "        if type(anno) != float:\n",
    "            who = r['who']\n",
    "            if type(who) == float: \n",
    "                x.append(who)\n",
    "                print(text_filename)\n",
    "        \n",
    "        text = r['0']\n",
    "        text_count.append(text)\n",
    "        \n",
    "        who = r['who']   \n",
    "        if who == '1.0':\n",
    "            my_annotation.append(who)\n",
    "        if who == '2.0':\n",
    "            their_annotation.append(who)\n",
    "        else:\n",
    "            num_words.append(who)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(their_annotation) # = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7912"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done' # all\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done\\\\1844-1871'\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done\\\\1871-1879'\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done\\\\1880-1889'\n",
    "path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done\\\\1890-1905'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\brev_dacy_medium.csv', converters={'dacy_medium': literal_eval})\n",
    "\n",
    "texts = []\n",
    "file_names = []\n",
    "\n",
    "for filename in all_files: \n",
    "    brev_filename = filename\n",
    "    brev_filename = re.match(r'.*\\\\(.*).csv', brev_filename)\n",
    "    brev_filename = brev_filename.group(1)\n",
    "    \n",
    "    for i,r in csv_df.iterrows():\n",
    "        files = r['files']\n",
    "        if files == brev_filename:\n",
    "            text = r['text']\n",
    "            text = re.split(r'[.!?]+', text)\n",
    "            for sent in text:\n",
    "                texts.append(sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>text</th>\n",
       "      <th>spacy_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREV_B1844-1871ht_18670308FH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREV_B1844-1871ht_B18260306NTB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREV_B1844-1871ht_B18440520PL</td>\n",
       "      <td>Du maa virkelig undskylde, at jeg først nu bes...</td>\n",
       "      <td>[('PER', 'Hedevall'), ('PER', 'Reimann'), ('OR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREV_B1844-1871ht_B18441006HSte</td>\n",
       "      <td>Tilgiv at jeg ikke før har besvaret Dit Brev, ...</td>\n",
       "      <td>[('ORG', 'Din Confirmation'), ('PER', 'Reimann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREV_B1844-1871ht_B18450801AWE</td>\n",
       "      <td>\\nJomfru M: Wahl hilses venskabeligst fra</td>\n",
       "      <td>[('PER', 'Wahl')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Hjerteligste</td>\n",
       "      <td>\\nHjerteligste ønsker!Tør desværre ikke selv p...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Med_udtrykket</td>\n",
       "      <td>\\n\\nMed udtrykket af min sympati for komitéens...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Tallene</td>\n",
       "      <td>\\nTallene må utvilsomt være skrevne af mig sel...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Wenn_Sie</td>\n",
       "      <td>\\n\\n\\n Wenn Sie keine andere Verwendung für Ih...</td>\n",
       "      <td>[('PER', 'Sie abends bei uns ohne')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>BREV_B1890-1905ht_BudatWA</td>\n",
       "      <td>\\nHjertelig velkommen når De vil! For resten v...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2449 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        files  \\\n",
       "0                BREV_B1844-1871ht_18670308FH   \n",
       "1              BREV_B1844-1871ht_B18260306NTB   \n",
       "2               BREV_B1844-1871ht_B18440520PL   \n",
       "3             BREV_B1844-1871ht_B18441006HSte   \n",
       "4              BREV_B1844-1871ht_B18450801AWE   \n",
       "...                                       ...   \n",
       "2444   BREV_B1890-1905ht_BudatNN_Hjerteligste   \n",
       "2445  BREV_B1890-1905ht_BudatNN_Med_udtrykket   \n",
       "2446        BREV_B1890-1905ht_BudatNN_Tallene   \n",
       "2447       BREV_B1890-1905ht_BudatNN_Wenn_Sie   \n",
       "2448                BREV_B1890-1905ht_BudatWA   \n",
       "\n",
       "                                                   text  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2     Du maa virkelig undskylde, at jeg først nu bes...   \n",
       "3     Tilgiv at jeg ikke før har besvaret Dit Brev, ...   \n",
       "4             \\nJomfru M: Wahl hilses venskabeligst fra   \n",
       "...                                                 ...   \n",
       "2444  \\nHjerteligste ønsker!Tør desværre ikke selv p...   \n",
       "2445  \\n\\nMed udtrykket af min sympati for komitéens...   \n",
       "2446  \\nTallene må utvilsomt være skrevne af mig sel...   \n",
       "2447  \\n\\n\\n Wenn Sie keine andere Verwendung für Ih...   \n",
       "2448  \\nHjertelig velkommen når De vil! For resten v...   \n",
       "\n",
       "                                           spacy_medium  \n",
       "0                                                    []  \n",
       "1                                                    []  \n",
       "2     [('PER', 'Hedevall'), ('PER', 'Reimann'), ('OR...  \n",
       "3     [('ORG', 'Din Confirmation'), ('PER', 'Reimann...  \n",
       "4                                     [('PER', 'Wahl')]  \n",
       "...                                                 ...  \n",
       "2444                                                 []  \n",
       "2445                                                 []  \n",
       "2446                                                 []  \n",
       "2447               [('PER', 'Sie abends bei uns ohne')]  \n",
       "2448                                                 []  \n",
       "\n",
       "[2449 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\brev_spacy_medium.csv', converters={'dacy_medium': literal_eval})\n",
    "csv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------- dacy medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253\n",
      "1198\n",
      "{'exact': {'count': 120,\n",
      "           'f1_score': 88.41245046396288,\n",
      "           'precision': 90.60557609469569,\n",
      "           'recall': 87.95284487935244},\n",
      " 'partial': {'count': 120,\n",
      "             'f1_score': 94.93407715828619,\n",
      "             'precision': 97.3491791992667,\n",
      "             'recall': 94.56998186400676},\n",
      " 'strict': {'count': 120,\n",
      "            'f1_score': 80.67605077724096,\n",
      "            'precision': 82.26586264044344,\n",
      "            'recall': 80.49158706471447},\n",
      " 'type': {'count': 120,\n",
      "          'f1_score': 91.50710986030872,\n",
      "          'precision': 93.31969352696738,\n",
      "          'recall': 91.53582606233091}}\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\brev_dacy_medium.csv', converters={'dacy_medium': literal_eval})\n",
    "\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\annotations\\\\done' # MISC Version\n",
    "#all_files = glob.glob(path + \"/*.csv\")\n",
    "#csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\brev_dacy_medium.csv', converters={'dacy_medium': literal_eval})\n",
    "\n",
    "ground_truths = []\n",
    "predictions = []\n",
    "texts = []\n",
    "file_names = []\n",
    "\n",
    "for filename in all_files:\n",
    "    text_filename = filename\n",
    "    text_filename = re.sub(\"csv\", \"txt\", text_filename)\n",
    "    text_filename = re.sub(\"annotations\", \"txt\", text_filename)\n",
    "    text_filename = re.sub(\"done\", \"brev_p\", text_filename)\n",
    "    \n",
    "    with open(text_filename, 'r', encoding = 'utf-8') as txt_file:\n",
    "        text = txt_file.read()\n",
    "        text = text.strip().replace(\"\\n\", \"\")\n",
    "        texts.append(text)\n",
    "        \n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    li_1 = []\n",
    "    li_2 = []\n",
    "\n",
    "    for i,r in df.iterrows():\n",
    "        annotation = r['human_annotation']\n",
    "        annotation = str(annotation)\n",
    "        annotation = annotation.split(\";\")\n",
    "        annotation = str(annotation)\n",
    "        annotation = re.sub(\"'\", '', annotation)\n",
    "        annotation = re.sub(\"\\[\", '', annotation)\n",
    "        annotation = re.sub(\"\\]\", '', annotation)\n",
    "        li_1.append(annotation)\n",
    "        end_list_a = []\n",
    "\n",
    "    for i in li_1:\n",
    "        if re.match(r'nan', i):\n",
    "            pass\n",
    "        else:\n",
    "            words = re.match(r'(\\()(\\w.*), {1} ?(:? ?\\w.* ?\\w*)(\\))', i)\n",
    "            elem_1 = words.group(2)\n",
    "            elem_2 = words.group(3)\n",
    "            full = (elem_1, elem_2)\n",
    "            end_list_a.append(full)\n",
    "                \n",
    "    ground_truths.append(end_list_a)\n",
    "\n",
    "\n",
    "    brev_filename = filename\n",
    "    brev_filename = re.match(r'.*done\\\\(.*).csv', brev_filename)\n",
    "    brev_filename = brev_filename.group(1)\n",
    "    \n",
    "    for i,r in csv_df.iterrows():\n",
    "        files = r['files']\n",
    "        if files == brev_filename:\n",
    "            dacy_medium = r['dacy_medium']\n",
    "            predictions.append(dacy_medium)\n",
    "            f = r['files']\n",
    "            file_names.append(f)\n",
    "    \n",
    "\n",
    "lists = {'filename': file_names, 'texts': texts, 'ground_truths': ground_truths, 'dacy_medium': predictions}\n",
    "\n",
    "df_dm_m = pd.DataFrame.from_dict(lists, orient = 'index')\n",
    "df_dm_m = df_dm_m.transpose()\n",
    "\n",
    "count = 0\n",
    "for e in ground_truths:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for e in predictions:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "ground_truths_r = ground_truths\n",
    "\n",
    "#dacy_m_result = muc.evaluate_all(predictions, ground_truths_r * 1, texts, verbose=True)\n",
    "pprint.pprint(dacy_m_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\\")\n",
    "#path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\\") #misc version\n",
    "df_dm_m.to_csv(os.path.join(path,r'dacy_medium_w_annotation.csv'), encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>texts</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>dacy_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREV_B1844-1871ht_B18450801AWE</td>\n",
       "      <td>Jomfru M: Wahl hilses venskabeligst fra</td>\n",
       "      <td>[(PER, M: Wahl)]</td>\n",
       "      <td>[(PER, Jomfru M), (PER, Wahl)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREV_B1844-1871ht_B18461207JCP</td>\n",
       "      <td>Opfordret af Deres Velbaarenhed til at erklære...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen), (PE...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen), (PE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREV_B1844-1871ht_B18491015OS</td>\n",
       "      <td>Dit sidste Brev har i dobbelt Henseende glædet...</td>\n",
       "      <td>[(PER, Due), (MISC, C.)]</td>\n",
       "      <td>[(MISC, Buxetøiet), (PER, Olaf Tr), (PER, C.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREV_B1844-1871ht_B18500105OS</td>\n",
       "      <td>Gjennem din sidste Skrivelse har jeg modtaget ...</td>\n",
       "      <td>[(MISC, Catilinas), (MISC, C.), (MISC, Olaf T....</td>\n",
       "      <td>[(PER, Catilinas), (PER, C.), (PER, Olaf T.), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREV_B1844-1871ht_B18500728AkKoll</td>\n",
       "      <td>Undertegnede opgiver herved at have læst 12te ...</td>\n",
       "      <td>[(MISC, Homers Iliade)]</td>\n",
       "      <td>[(MISC, Homers Iliade)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>BREV_B1890-1905ht_Budat1891JLi</td>\n",
       "      <td>Jernbane fra Neapel til Castelamare (omtr. 1¼ ...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18930116NN_Fest</td>\n",
       "      <td>De store Fortjenester, Fru Camilla Collett har...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Collett), (ORG,...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Collett), (ORG,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18950427SuI</td>\n",
       "      <td>Dit brev af 18de fik jeg her den 23de; men jeg...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189504SuI</td>\n",
       "      <td>Jeg skriver idag bare nogle få ord for at du k...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Begliot), (PER, Lina), (...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum</td>\n",
       "      <td>Et Tidsrum af 12 Aar er forløbet, siden den si...</td>\n",
       "      <td>[(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...</td>\n",
       "      <td>[(MISC, den 6te), (LOC, Trondhjem), (LOC, Kris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename  \\\n",
       "0                BREV_B1844-1871ht_B18450801AWE   \n",
       "1                BREV_B1844-1871ht_B18461207JCP   \n",
       "2                 BREV_B1844-1871ht_B18491015OS   \n",
       "3                 BREV_B1844-1871ht_B18500105OS   \n",
       "4             BREV_B1844-1871ht_B18500728AkKoll   \n",
       "..                                          ...   \n",
       "115              BREV_B1890-1905ht_Budat1891JLi   \n",
       "116      BREV_B1890-1905ht_Budat18930116NN_Fest   \n",
       "117          BREV_B1890-1905ht_Budat18950427SuI   \n",
       "118            BREV_B1890-1905ht_Budat189504SuI   \n",
       "119  BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum   \n",
       "\n",
       "                                                 texts  \\\n",
       "0              Jomfru M: Wahl hilses venskabeligst fra   \n",
       "1    Opfordret af Deres Velbaarenhed til at erklære...   \n",
       "2    Dit sidste Brev har i dobbelt Henseende glædet...   \n",
       "3    Gjennem din sidste Skrivelse har jeg modtaget ...   \n",
       "4    Undertegnede opgiver herved at have læst 12te ...   \n",
       "..                                                 ...   \n",
       "115  Jernbane fra Neapel til Castelamare (omtr. 1¼ ...   \n",
       "116  De store Fortjenester, Fru Camilla Collett har...   \n",
       "117  Dit brev af 18de fik jeg her den 23de; men jeg...   \n",
       "118  Jeg skriver idag bare nogle få ord for at du k...   \n",
       "119  Et Tidsrum af 12 Aar er forløbet, siden den si...   \n",
       "\n",
       "                                         ground_truths  \\\n",
       "0                                     [(PER, M: Wahl)]   \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen), (PE...   \n",
       "2                             [(PER, Due), (MISC, C.)]   \n",
       "3    [(MISC, Catilinas), (MISC, C.), (MISC, Olaf T....   \n",
       "4                              [(MISC, Homers Iliade)]   \n",
       "..                                                 ...   \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...   \n",
       "116  [(PER, Camilla Collett), (PER, Collett), (ORG,...   \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...   \n",
       "118  [(PER, Sigurd), (PER, Begliot), (PER, Lina), (...   \n",
       "119  [(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...   \n",
       "\n",
       "                                           dacy_medium  \n",
       "0                       [(PER, Jomfru M), (PER, Wahl)]  \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen), (PE...  \n",
       "2       [(MISC, Buxetøiet), (PER, Olaf Tr), (PER, C.)]  \n",
       "3    [(PER, Catilinas), (PER, C.), (PER, Olaf T.), ...  \n",
       "4                              [(MISC, Homers Iliade)]  \n",
       "..                                                 ...  \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...  \n",
       "116  [(PER, Camilla Collett), (PER, Collett), (ORG,...  \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...  \n",
       "118  [(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...  \n",
       "119  [(MISC, den 6te), (LOC, Trondhjem), (LOC, Kris...  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dm_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------- spacy trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253\n",
      "1191\n",
      "{'exact': {'count': 120,\n",
      "           'f1_score': 91.77668562049371,\n",
      "           'precision': 94.36178642803594,\n",
      "           'recall': 91.09158978063944},\n",
      " 'partial': {'count': 120,\n",
      "             'f1_score': 98.61213884570559,\n",
      "             'precision': 101.52486006644011,\n",
      "             'recall': 97.77653960871068},\n",
      " 'strict': {'count': 120,\n",
      "            'f1_score': 85.96022343014045,\n",
      "            'precision': 88.42984895983912,\n",
      "            'recall': 85.23692044470205},\n",
      " 'type': {'count': 120,\n",
      "          'f1_score': 97.05017425917328,\n",
      "          'precision': 99.9830817473083,\n",
      "          'recall': 96.14392158887708}}\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\brev_spacy_trf.csv', converters={'spacy_trf': literal_eval})\n",
    "\n",
    "\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\annotations\\\\done' # MISC Version\n",
    "#all_files = glob.glob(path + \"/*.csv\")\n",
    "#csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\brev_spacy_trf.csv', converters={'spacy_trf': literal_eval})\n",
    "\n",
    "\n",
    "predictions = []\n",
    "ground_truths = []\n",
    "file_names = []\n",
    "\n",
    "for filename in all_files:\n",
    "    brev_filename = filename\n",
    "    brev_filename = re.match(r'.*done\\\\(.*).csv', brev_filename)\n",
    "    brev_filename = brev_filename.group(1)\n",
    "    \n",
    "    for i,r in csv_df.iterrows():\n",
    "        files = r['files']\n",
    "        if files == brev_filename:\n",
    "            spacy_trf = r['spacy_trf']\n",
    "            predictions.append(spacy_trf)\n",
    "            f = r['files']\n",
    "            file_names.append(f)\n",
    "      \n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    li_1 = []\n",
    "\n",
    "    for i,r in df.iterrows():\n",
    "        annotation = r['human_annotation']\n",
    "        annotation = str(annotation)\n",
    "        annotation = annotation.split(\";\")\n",
    "        annotation = str(annotation)\n",
    "        annotation = re.sub(\"'\", '', annotation)\n",
    "        annotation = re.sub(\"\\[\", '', annotation)\n",
    "        annotation = re.sub(\"\\]\", '', annotation)\n",
    "        li_1.append(annotation)\n",
    "        end_list_a = []\n",
    "\n",
    "    for i in li_1:\n",
    "        if re.match(r'nan', i):\n",
    "            pass\n",
    "        else:\n",
    "            words = re.match(r'(\\()(\\w.*), {1} ?(:? ?\\w.* ?\\w*)(\\))', i)\n",
    "            elem_1 = words.group(2)\n",
    "            elem_2 = words.group(3)\n",
    "            full = (elem_1, elem_2)\n",
    "            end_list_a.append(full)\n",
    "                \n",
    "    ground_truths.append(end_list_a)\n",
    "    \n",
    "    \n",
    "lists = {'filenames': file_names, 'texts': texts, 'ground_truths': ground_truths, 'spacy_trf': predictions}\n",
    "\n",
    "df_st = pd.DataFrame.from_dict(lists, orient = 'index')\n",
    "df_st = df_st.transpose()\n",
    "\n",
    "count = 0\n",
    "for e in ground_truths:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for e in predictions:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "ground_truths_r = ground_truths\n",
    "\n",
    "\n",
    "#spacy_trf_result = muc.evaluate_all(predictions, ground_truths_r * 1, texts, verbose=True)\n",
    "pprint.pprint(spacy_trf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>texts</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>spacy_trf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREV_B1844-1871ht_B18450801AWE</td>\n",
       "      <td>Jomfru M: Wahl hilses venskabeligst fra</td>\n",
       "      <td>[(PER, M: Wahl)]</td>\n",
       "      <td>[(PER, Wahl)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREV_B1844-1871ht_B18461207JCP</td>\n",
       "      <td>Opfordret af Deres Velbaarenhed til at erklære...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen), (PE...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen født)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREV_B1844-1871ht_B18491015OS</td>\n",
       "      <td>Dit sidste Brev har i dobbelt Henseende glædet...</td>\n",
       "      <td>[(PER, Due), (MISC, C.)]</td>\n",
       "      <td>[(PER, Due), (LOC, Buxetøiet), (PER, Olaf Tr),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREV_B1844-1871ht_B18500105OS</td>\n",
       "      <td>Gjennem din sidste Skrivelse har jeg modtaget ...</td>\n",
       "      <td>[(MISC, Catilinas), (MISC, C.), (MISC, Olaf T....</td>\n",
       "      <td>[(PER, Catilinas), (PER, C.), (PER, Olaf T.), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREV_B1844-1871ht_B18500728AkKoll</td>\n",
       "      <td>Undertegnede opgiver herved at have læst 12te ...</td>\n",
       "      <td>[(MISC, Homers Iliade)]</td>\n",
       "      <td>[(MISC, Homers Iliade)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>BREV_B1890-1905ht_Budat1891JLi</td>\n",
       "      <td>Jernbane fra Neapel til Castelamare (omtr. 1¼ ...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18930116NN_Fest</td>\n",
       "      <td>De store Fortjenester, Fru Camilla Collett har...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Collett), (ORG,...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Collett), (ORG,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18950427SuI</td>\n",
       "      <td>Dit brev af 18de fik jeg her den 23de; men jeg...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189504SuI</td>\n",
       "      <td>Jeg skriver idag bare nogle få ord for at du k...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Begliot), (PER, Lina), (...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum</td>\n",
       "      <td>Et Tidsrum af 12 Aar er forløbet, siden den si...</td>\n",
       "      <td>[(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...</td>\n",
       "      <td>[(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      filenames  \\\n",
       "0                BREV_B1844-1871ht_B18450801AWE   \n",
       "1                BREV_B1844-1871ht_B18461207JCP   \n",
       "2                 BREV_B1844-1871ht_B18491015OS   \n",
       "3                 BREV_B1844-1871ht_B18500105OS   \n",
       "4             BREV_B1844-1871ht_B18500728AkKoll   \n",
       "..                                          ...   \n",
       "115              BREV_B1890-1905ht_Budat1891JLi   \n",
       "116      BREV_B1890-1905ht_Budat18930116NN_Fest   \n",
       "117          BREV_B1890-1905ht_Budat18950427SuI   \n",
       "118            BREV_B1890-1905ht_Budat189504SuI   \n",
       "119  BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum   \n",
       "\n",
       "                                                 texts  \\\n",
       "0              Jomfru M: Wahl hilses venskabeligst fra   \n",
       "1    Opfordret af Deres Velbaarenhed til at erklære...   \n",
       "2    Dit sidste Brev har i dobbelt Henseende glædet...   \n",
       "3    Gjennem din sidste Skrivelse har jeg modtaget ...   \n",
       "4    Undertegnede opgiver herved at have læst 12te ...   \n",
       "..                                                 ...   \n",
       "115  Jernbane fra Neapel til Castelamare (omtr. 1¼ ...   \n",
       "116  De store Fortjenester, Fru Camilla Collett har...   \n",
       "117  Dit brev af 18de fik jeg her den 23de; men jeg...   \n",
       "118  Jeg skriver idag bare nogle få ord for at du k...   \n",
       "119  Et Tidsrum af 12 Aar er forløbet, siden den si...   \n",
       "\n",
       "                                         ground_truths  \\\n",
       "0                                     [(PER, M: Wahl)]   \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen), (PE...   \n",
       "2                             [(PER, Due), (MISC, C.)]   \n",
       "3    [(MISC, Catilinas), (MISC, C.), (MISC, Olaf T....   \n",
       "4                              [(MISC, Homers Iliade)]   \n",
       "..                                                 ...   \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...   \n",
       "116  [(PER, Camilla Collett), (PER, Collett), (ORG,...   \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...   \n",
       "118  [(PER, Sigurd), (PER, Begliot), (PER, Lina), (...   \n",
       "119  [(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...   \n",
       "\n",
       "                                             spacy_trf  \n",
       "0                                        [(PER, Wahl)]  \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen født)...  \n",
       "2    [(PER, Due), (LOC, Buxetøiet), (PER, Olaf Tr),...  \n",
       "3    [(PER, Catilinas), (PER, C.), (PER, Olaf T.), ...  \n",
       "4                              [(MISC, Homers Iliade)]  \n",
       "..                                                 ...  \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...  \n",
       "116  [(PER, Camilla Collett), (PER, Collett), (ORG,...  \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...  \n",
       "118  [(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...  \n",
       "119  [(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\\")\n",
    "#path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\\") #misc version\n",
    "\n",
    "df_st.to_csv(os.path.join(path,r'spacy_trf_w_annotation.csv'), encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------- dacy large "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253\n",
      "1291\n",
      "{'exact': {'count': 120,\n",
      "           'f1_score': 98.08616975086863,\n",
      "           'precision': 97.77805428010035,\n",
      "           'recall': 99.32278936296402},\n",
      " 'partial': {'count': 120,\n",
      "             'f1_score': 103.15439069991105,\n",
      "             'precision': 102.73950730571127,\n",
      "             'recall': 104.54157724920088},\n",
      " 'strict': {'count': 120,\n",
      "            'f1_score': 91.79572422498259,\n",
      "            'precision': 91.67938502429067,\n",
      "            'recall': 92.7125047303753},\n",
      " 'type': {'count': 120,\n",
      "          'f1_score': 99.38012953349234,\n",
      "          'precision': 99.10044446329859,\n",
      "          'recall': 100.53053092838687}}\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\brev_dacy_large.csv', converters={'dacy_large': literal_eval})\n",
    "\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\annotations\\\\done' # MISC Version\n",
    "#all_files = glob.glob(path + \"/*.csv\")\n",
    "#csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\brev_dacy_large.csv', converters={'dacy_large': literal_eval})\n",
    "\n",
    "\n",
    "predictions = []\n",
    "ground_truths = []\n",
    "file_names = []\n",
    "\n",
    "for filename in all_files: \n",
    "    brev_filename = filename\n",
    "    brev_filename = re.match(r'.*done\\\\(.*).csv', brev_filename)\n",
    "    brev_filename = brev_filename.group(1)\n",
    "    \n",
    "    for i,r in csv_df.iterrows():\n",
    "        files = r['files']\n",
    "        if files == brev_filename:\n",
    "            dacy_large = r['dacy_large']\n",
    "            predictions.append(dacy_large)\n",
    "            f = r['files']\n",
    "            file_names.append(f)\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    li_1 = []\n",
    "\n",
    "    for i,r in df.iterrows():\n",
    "        annotation = r['human_annotation']\n",
    "        annotation = str(annotation)\n",
    "        annotation = annotation.split(\";\")\n",
    "        annotation = str(annotation)\n",
    "        annotation = re.sub(\"'\", '', annotation)\n",
    "        annotation = re.sub(\"\\[\", '', annotation)\n",
    "        annotation = re.sub(\"\\]\", '', annotation)\n",
    "        li_1.append(annotation)\n",
    "        end_list_a = []\n",
    "\n",
    "    for i in li_1:\n",
    "        if re.match(r'nan', i):\n",
    "            pass\n",
    "        else:\n",
    "            words = re.match(r'(\\()(\\w.*), {1} ?(:? ?\\w.* ?\\w*)(\\))', i)\n",
    "            elem_1 = words.group(2)\n",
    "            elem_2 = words.group(3)\n",
    "            full = (elem_1, elem_2)\n",
    "            end_list_a.append(full)\n",
    "                \n",
    "    ground_truths.append(end_list_a)\n",
    "    \n",
    "lists = {'filename': file_names, 'texts': texts, 'ground_truths': ground_truths, 'dacy_large': predictions}\n",
    "\n",
    "df_dl = pd.DataFrame.from_dict(lists, orient = 'index')\n",
    "df_dl = df_dl.transpose()\n",
    "\n",
    "count = 0\n",
    "for e in ground_truths:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for e in predictions:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "ground_truths_r = ground_truths\n",
    "\n",
    "#dacy_large_result = muc.evaluate_all(predictions, ground_truths_r * 1, texts, verbose=True)\n",
    "pprint.pprint(dacy_large_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>texts</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>dacy_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREV_B1844-1871ht_B18450801AWE</td>\n",
       "      <td>Jomfru M: Wahl hilses venskabeligst fra</td>\n",
       "      <td>[(PER, M: Wahl)]</td>\n",
       "      <td>[(PER, M: Wahl)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREV_B1844-1871ht_B18461207JCP</td>\n",
       "      <td>Opfordret af Deres Velbaarenhed til at erklære...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen), (PE...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen), (PE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREV_B1844-1871ht_B18491015OS</td>\n",
       "      <td>Dit sidste Brev har i dobbelt Henseende glædet...</td>\n",
       "      <td>[(PER, Due)]</td>\n",
       "      <td>[(PER, Olaf Tr), (PER, C.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREV_B1844-1871ht_B18500105OS</td>\n",
       "      <td>Gjennem din sidste Skrivelse har jeg modtaget ...</td>\n",
       "      <td>[(LOC, Thelemarken), (PER, Christian Lofthuus)...</td>\n",
       "      <td>[(PER, Catilinas), (PER, C.), (LOC, indre Geha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREV_B1844-1871ht_B18500728AkKoll</td>\n",
       "      <td>Undertegnede opgiver herved at have læst 12te ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>BREV_B1890-1905ht_Budat1891JLi</td>\n",
       "      <td>Jernbane fra Neapel til Castelamare (omtr. 1¼ ...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18930116NN_Fest</td>\n",
       "      <td>De store Fortjenester, Fru Camilla Collett har...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Collett), (ORG,...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Fru Collett), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18950427SuI</td>\n",
       "      <td>Dit brev af 18de fik jeg her den 23de; men jeg...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189504SuI</td>\n",
       "      <td>Jeg skriver idag bare nogle få ord for at du k...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Begliot), (PER, Lina), (...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum</td>\n",
       "      <td>Et Tidsrum af 12 Aar er forløbet, siden den si...</td>\n",
       "      <td>[(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...</td>\n",
       "      <td>[(LOC, Trondhjem), (LOC, Fanen), (LOC, Stræv),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename  \\\n",
       "0                BREV_B1844-1871ht_B18450801AWE   \n",
       "1                BREV_B1844-1871ht_B18461207JCP   \n",
       "2                 BREV_B1844-1871ht_B18491015OS   \n",
       "3                 BREV_B1844-1871ht_B18500105OS   \n",
       "4             BREV_B1844-1871ht_B18500728AkKoll   \n",
       "..                                          ...   \n",
       "115              BREV_B1890-1905ht_Budat1891JLi   \n",
       "116      BREV_B1890-1905ht_Budat18930116NN_Fest   \n",
       "117          BREV_B1890-1905ht_Budat18950427SuI   \n",
       "118            BREV_B1890-1905ht_Budat189504SuI   \n",
       "119  BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum   \n",
       "\n",
       "                                                 texts  \\\n",
       "0              Jomfru M: Wahl hilses venskabeligst fra   \n",
       "1    Opfordret af Deres Velbaarenhed til at erklære...   \n",
       "2    Dit sidste Brev har i dobbelt Henseende glædet...   \n",
       "3    Gjennem din sidste Skrivelse har jeg modtaget ...   \n",
       "4    Undertegnede opgiver herved at have læst 12te ...   \n",
       "..                                                 ...   \n",
       "115  Jernbane fra Neapel til Castelamare (omtr. 1¼ ...   \n",
       "116  De store Fortjenester, Fru Camilla Collett har...   \n",
       "117  Dit brev af 18de fik jeg her den 23de; men jeg...   \n",
       "118  Jeg skriver idag bare nogle få ord for at du k...   \n",
       "119  Et Tidsrum af 12 Aar er forløbet, siden den si...   \n",
       "\n",
       "                                         ground_truths  \\\n",
       "0                                     [(PER, M: Wahl)]   \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen), (PE...   \n",
       "2                                         [(PER, Due)]   \n",
       "3    [(LOC, Thelemarken), (PER, Christian Lofthuus)...   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...   \n",
       "116  [(PER, Camilla Collett), (PER, Collett), (ORG,...   \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...   \n",
       "118  [(PER, Sigurd), (PER, Begliot), (PER, Lina), (...   \n",
       "119  [(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...   \n",
       "\n",
       "                                            dacy_large  \n",
       "0                                     [(PER, M: Wahl)]  \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen), (PE...  \n",
       "2                          [(PER, Olaf Tr), (PER, C.)]  \n",
       "3    [(PER, Catilinas), (PER, C.), (LOC, indre Geha...  \n",
       "4                                                   []  \n",
       "..                                                 ...  \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...  \n",
       "116  [(PER, Camilla Collett), (PER, Fru Collett), (...  \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...  \n",
       "118  [(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...  \n",
       "119  [(LOC, Trondhjem), (LOC, Fanen), (LOC, Stræv),...  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\\")\n",
    "#path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\\") #misc version\n",
    "\n",
    "df_dl.to_csv(os.path.join(path,r'dacy_large_w_annotation.csv'), encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------- dacy small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253\n",
      "1514\n",
      "{'exact': {'count': 120,\n",
      "           'f1_score': 89.45569158528252,\n",
      "           'precision': 86.53397814278424,\n",
      "           'recall': 95.86549393913194},\n",
      " 'partial': {'count': 120,\n",
      "             'f1_score': 94.7079214289534,\n",
      "             'precision': 91.28505497142044,\n",
      "             'recall': 102.14974271177653},\n",
      " 'strict': {'count': 120,\n",
      "            'f1_score': 78.83394798553415,\n",
      "            'precision': 76.47666591021432,\n",
      "            'recall': 84.18607366157586},\n",
      " 'type': {'count': 120,\n",
      "          'f1_score': 85.07206550906429,\n",
      "          'precision': 81.96264545636025,\n",
      "          'recall': 91.83923711815518}}\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\brev_dacy_small.csv', converters={'dacy_small': literal_eval})\n",
    "\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\annotations\\\\done' # MISC Version\n",
    "#all_files = glob.glob(path + \"/*.csv\")\n",
    "#csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\brev_dacy_small.csv', converters={'dacy_small': literal_eval})\n",
    "\n",
    "\n",
    "predictions = []\n",
    "ground_truths = []\n",
    "file_names = []\n",
    "\n",
    "for filename in all_files:\n",
    "    brev_filename = filename\n",
    "    brev_filename = re.match(r'.*done\\\\(.*).csv', brev_filename)\n",
    "    brev_filename = brev_filename.group(1)\n",
    "    \n",
    "    for i,r in csv_df.iterrows():\n",
    "        files = r['files']\n",
    "        if files == brev_filename:\n",
    "            dacy_small = r['dacy_small']\n",
    "            predictions.append(dacy_small)\n",
    "            f = r['files']\n",
    "            file_names.append(f)\n",
    "            \n",
    "    df = pd.read_csv(filename)\n",
    "    li_1 = []\n",
    "\n",
    "    for i,r in df.iterrows():\n",
    "        annotation = r['human_annotation']\n",
    "        annotation = str(annotation)\n",
    "        annotation = annotation.split(\";\")\n",
    "        annotation = str(annotation)\n",
    "        annotation = re.sub(\"'\", '', annotation)\n",
    "        annotation = re.sub(\"\\[\", '', annotation)\n",
    "        annotation = re.sub(\"\\]\", '', annotation)\n",
    "        li_1.append(annotation)\n",
    "        end_list_a = []\n",
    "\n",
    "    for i in li_1:\n",
    "        if re.match(r'nan', i):\n",
    "            pass\n",
    "        else:\n",
    "            words = re.match(r'(\\()(\\w.*), {1} ?(:? ?\\w.* ?\\w*)(\\))', i)\n",
    "            elem_1 = words.group(2)\n",
    "            elem_2 = words.group(3)\n",
    "            full = (elem_1, elem_2)\n",
    "            end_list_a.append(full)\n",
    "                \n",
    "    ground_truths.append(end_list_a)\n",
    "    \n",
    "lists = {'filename': file_names, 'texts': texts, 'ground_truths': ground_truths, 'dacy_small': predictions}\n",
    "\n",
    "df_ds = pd.DataFrame.from_dict(lists, orient = 'index')\n",
    "df_ds = df_ds.transpose()\n",
    "\n",
    "count = 0\n",
    "for e in ground_truths:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for e in predictions:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "ground_truths_r = ground_truths\n",
    "\n",
    "#dacy_small_result = muc.evaluate_all(predictions, ground_truths_r * 1, texts, verbose=True)\n",
    "pprint.pprint(dacy_small_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>texts</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>dacy_small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREV_B1844-1871ht_B18450801AWE</td>\n",
       "      <td>Jomfru M: Wahl hilses venskabeligst fra</td>\n",
       "      <td>[(PER, M: Wahl)]</td>\n",
       "      <td>[(PER, M), (PER, Wahl)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREV_B1844-1871ht_B18461207JCP</td>\n",
       "      <td>Opfordret af Deres Velbaarenhed til at erklære...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen), (PE...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen), (PE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREV_B1844-1871ht_B18491015OS</td>\n",
       "      <td>Dit sidste Brev har i dobbelt Henseende glædet...</td>\n",
       "      <td>[(PER, Due)]</td>\n",
       "      <td>[(LOC, Noget der), (PER, Due), (PER, Olaf Tr),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREV_B1844-1871ht_B18500105OS</td>\n",
       "      <td>Gjennem din sidste Skrivelse har jeg modtaget ...</td>\n",
       "      <td>[(LOC, Thelemarken), (PER, Christian Lofthuus)...</td>\n",
       "      <td>[(PER, Catilinas), (PER, C.), (ORG, Directione...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREV_B1844-1871ht_B18500728AkKoll</td>\n",
       "      <td>Undertegnede opgiver herved at have læst 12te ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(ORG, Homers Iliade)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>BREV_B1890-1905ht_Budat1891JLi</td>\n",
       "      <td>Jernbane fra Neapel til Castelamare (omtr. 1¼ ...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18930116NN_Fest</td>\n",
       "      <td>De store Fortjenester, Fru Camilla Collett har...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Collett), (ORG,...</td>\n",
       "      <td>[(PER, Fru Camilla Collett), (LOC, Samfund), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18950427SuI</td>\n",
       "      <td>Dit brev af 18de fik jeg her den 23de; men jeg...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189504SuI</td>\n",
       "      <td>Jeg skriver idag bare nogle få ord for at du k...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Begliot), (PER, Lina), (...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum</td>\n",
       "      <td>Et Tidsrum af 12 Aar er forløbet, siden den si...</td>\n",
       "      <td>[(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...</td>\n",
       "      <td>[(LOC, Trondhjem), (LOC, Stand), (LOC, Landets...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename  \\\n",
       "0                BREV_B1844-1871ht_B18450801AWE   \n",
       "1                BREV_B1844-1871ht_B18461207JCP   \n",
       "2                 BREV_B1844-1871ht_B18491015OS   \n",
       "3                 BREV_B1844-1871ht_B18500105OS   \n",
       "4             BREV_B1844-1871ht_B18500728AkKoll   \n",
       "..                                          ...   \n",
       "115              BREV_B1890-1905ht_Budat1891JLi   \n",
       "116      BREV_B1890-1905ht_Budat18930116NN_Fest   \n",
       "117          BREV_B1890-1905ht_Budat18950427SuI   \n",
       "118            BREV_B1890-1905ht_Budat189504SuI   \n",
       "119  BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum   \n",
       "\n",
       "                                                 texts  \\\n",
       "0              Jomfru M: Wahl hilses venskabeligst fra   \n",
       "1    Opfordret af Deres Velbaarenhed til at erklære...   \n",
       "2    Dit sidste Brev har i dobbelt Henseende glædet...   \n",
       "3    Gjennem din sidste Skrivelse har jeg modtaget ...   \n",
       "4    Undertegnede opgiver herved at have læst 12te ...   \n",
       "..                                                 ...   \n",
       "115  Jernbane fra Neapel til Castelamare (omtr. 1¼ ...   \n",
       "116  De store Fortjenester, Fru Camilla Collett har...   \n",
       "117  Dit brev af 18de fik jeg her den 23de; men jeg...   \n",
       "118  Jeg skriver idag bare nogle få ord for at du k...   \n",
       "119  Et Tidsrum af 12 Aar er forløbet, siden den si...   \n",
       "\n",
       "                                         ground_truths  \\\n",
       "0                                     [(PER, M: Wahl)]   \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen), (PE...   \n",
       "2                                         [(PER, Due)]   \n",
       "3    [(LOC, Thelemarken), (PER, Christian Lofthuus)...   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...   \n",
       "116  [(PER, Camilla Collett), (PER, Collett), (ORG,...   \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...   \n",
       "118  [(PER, Sigurd), (PER, Begliot), (PER, Lina), (...   \n",
       "119  [(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...   \n",
       "\n",
       "                                            dacy_small  \n",
       "0                              [(PER, M), (PER, Wahl)]  \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen), (PE...  \n",
       "2    [(LOC, Noget der), (PER, Due), (PER, Olaf Tr),...  \n",
       "3    [(PER, Catilinas), (PER, C.), (ORG, Directione...  \n",
       "4                               [(ORG, Homers Iliade)]  \n",
       "..                                                 ...  \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...  \n",
       "116  [(PER, Fru Camilla Collett), (LOC, Samfund), (...  \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...  \n",
       "118  [(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...  \n",
       "119  [(LOC, Trondhjem), (LOC, Stand), (LOC, Landets...  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\\")\n",
    "#path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\\") #misc version\n",
    "df_ds.to_csv(os.path.join(path,r'dacy_small_w_annotation.csv'), encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "------------- spacy small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253\n",
      "1991\n",
      "{'exact': {'count': 120,\n",
      "           'f1_score': 69.89847227512928,\n",
      "           'precision': 71.7556308766165,\n",
      "           'recall': 75.47600583679782},\n",
      " 'partial': {'count': 120,\n",
      "             'f1_score': 74.31283888720297,\n",
      "             'precision': 76.35996414311525,\n",
      "             'recall': 80.85151067019561},\n",
      " 'strict': {'count': 120,\n",
      "            'f1_score': 53.51711834923485,\n",
      "            'precision': 54.55563379419915,\n",
      "            'recall': 58.104050909488556},\n",
      " 'type': {'count': 120,\n",
      "          'f1_score': 57.92738623532905,\n",
      "          'precision': 59.442791479760324,\n",
      "          'recall': 62.925510625285604}}\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\brev_spacy_small.csv', converters={'spacy_small': literal_eval})\n",
    "\n",
    "\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\annotations\\\\done' # MISC Version\n",
    "#all_files = glob.glob(path + \"/*.csv\")\n",
    "#csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\brev_spacy_small.csv', converters={'spacy_small': literal_eval})\n",
    "\n",
    "\n",
    "ground_truths = []\n",
    "predictions = []\n",
    "file_names = []\n",
    "\n",
    "for filename in all_files:\n",
    "    brev_filename = filename\n",
    "    brev_filename = re.match(r'.*done\\\\(.*).csv', brev_filename)\n",
    "    brev_filename = brev_filename.group(1)\n",
    "   \n",
    "    for i,r in csv_df.iterrows():\n",
    "        files = r['files']\n",
    "        if files == brev_filename:\n",
    "            spacy_small = r['spacy_small']\n",
    "            predictions.append(spacy_small)\n",
    "            f = r['files']\n",
    "            file_names.append(f)\n",
    "            \n",
    "    df = pd.read_csv(filename)\n",
    "    li_1 = []\n",
    "\n",
    "    for i,r in df.iterrows():\n",
    "        annotation = r['human_annotation']\n",
    "        annotation = str(annotation)\n",
    "        annotation = annotation.split(\";\")\n",
    "        annotation = str(annotation)\n",
    "        annotation = re.sub(\"'\", '', annotation)\n",
    "        annotation = re.sub(\"\\[\", '', annotation)\n",
    "        annotation = re.sub(\"\\]\", '', annotation)\n",
    "        li_1.append(annotation)\n",
    "        end_list_a = []\n",
    "\n",
    "    for i in li_1:\n",
    "        if re.match(r'nan', i):\n",
    "            pass\n",
    "        else:\n",
    "            words = re.match(r'(\\()(\\w.*), {1} ?(:? ?\\w.* ?\\w*)(\\))', i)\n",
    "            elem_1 = words.group(2)\n",
    "            elem_2 = words.group(3)\n",
    "            full = (elem_1, elem_2)\n",
    "            end_list_a.append(full)\n",
    "                \n",
    "    ground_truths.append(end_list_a)\n",
    "    \n",
    "lists = {'filename': file_names, 'texts': texts, 'ground_truths': ground_truths, 'spacy_small': predictions}\n",
    "\n",
    "df_ss = pd.DataFrame.from_dict(lists, orient = 'index')\n",
    "df_ss = df_ss.transpose()\n",
    "\n",
    "count = 0\n",
    "for e in ground_truths:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for e in predictions:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "ground_truths_r = ground_truths\n",
    "\n",
    "#spacy_small_result = muc.evaluate_all(predictions, ground_truths_r * 1, texts, verbose=True)\n",
    "pprint.pprint(spacy_small_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>texts</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>spacy_small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREV_B1844-1871ht_B18450801AWE</td>\n",
       "      <td>Jomfru M: Wahl hilses venskabeligst fra</td>\n",
       "      <td>[(PER, M: Wahl)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREV_B1844-1871ht_B18461207JCP</td>\n",
       "      <td>Opfordret af Deres Velbaarenhed til at erklære...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen), (PE...</td>\n",
       "      <td>[(ORG, Pigen Else Sophie Jensdatter Birkedalen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREV_B1844-1871ht_B18491015OS</td>\n",
       "      <td>Dit sidste Brev har i dobbelt Henseende glædet...</td>\n",
       "      <td>[(PER, Due)]</td>\n",
       "      <td>[(LOC, Skrivelse), (PER, Opbrusning), (PER, Ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREV_B1844-1871ht_B18500105OS</td>\n",
       "      <td>Gjennem din sidste Skrivelse har jeg modtaget ...</td>\n",
       "      <td>[(LOC, Thelemarken), (PER, Christian Lofthuus)...</td>\n",
       "      <td>[(PER, Skrivelse), (PER, Catilinas), (PER, Mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREV_B1844-1871ht_B18500728AkKoll</td>\n",
       "      <td>Undertegnede opgiver herved at have læst 12te ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(ORG, Homers Iliade)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>BREV_B1890-1905ht_Budat1891JLi</td>\n",
       "      <td>Jernbane fra Neapel til Castelamare (omtr. 1¼ ...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "      <td>[(PER, Jernbane), (LOC, Neapel), (LOC, Castela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18930116NN_Fest</td>\n",
       "      <td>De store Fortjenester, Fru Camilla Collett har...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Collett), (ORG,...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Livs), (LOC, Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18950427SuI</td>\n",
       "      <td>Dit brev af 18de fik jeg her den 23de; men jeg...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "      <td>[(ORG, Sigurd), (PER, Christian Krohg), (ORG, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189504SuI</td>\n",
       "      <td>Jeg skriver idag bare nogle få ord for at du k...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Begliot), (PER, Lina), (...</td>\n",
       "      <td>[(ORG, Sigurd), (LOC, Bergliot), (PER, Lina), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum</td>\n",
       "      <td>Et Tidsrum af 12 Aar er forløbet, siden den si...</td>\n",
       "      <td>[(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...</td>\n",
       "      <td>[(ORG, 6te i Rækken), (LOC, Trondhjem), (ORG, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename  \\\n",
       "0                BREV_B1844-1871ht_B18450801AWE   \n",
       "1                BREV_B1844-1871ht_B18461207JCP   \n",
       "2                 BREV_B1844-1871ht_B18491015OS   \n",
       "3                 BREV_B1844-1871ht_B18500105OS   \n",
       "4             BREV_B1844-1871ht_B18500728AkKoll   \n",
       "..                                          ...   \n",
       "115              BREV_B1890-1905ht_Budat1891JLi   \n",
       "116      BREV_B1890-1905ht_Budat18930116NN_Fest   \n",
       "117          BREV_B1890-1905ht_Budat18950427SuI   \n",
       "118            BREV_B1890-1905ht_Budat189504SuI   \n",
       "119  BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum   \n",
       "\n",
       "                                                 texts  \\\n",
       "0              Jomfru M: Wahl hilses venskabeligst fra   \n",
       "1    Opfordret af Deres Velbaarenhed til at erklære...   \n",
       "2    Dit sidste Brev har i dobbelt Henseende glædet...   \n",
       "3    Gjennem din sidste Skrivelse har jeg modtaget ...   \n",
       "4    Undertegnede opgiver herved at have læst 12te ...   \n",
       "..                                                 ...   \n",
       "115  Jernbane fra Neapel til Castelamare (omtr. 1¼ ...   \n",
       "116  De store Fortjenester, Fru Camilla Collett har...   \n",
       "117  Dit brev af 18de fik jeg her den 23de; men jeg...   \n",
       "118  Jeg skriver idag bare nogle få ord for at du k...   \n",
       "119  Et Tidsrum af 12 Aar er forløbet, siden den si...   \n",
       "\n",
       "                                         ground_truths  \\\n",
       "0                                     [(PER, M: Wahl)]   \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen), (PE...   \n",
       "2                                         [(PER, Due)]   \n",
       "3    [(LOC, Thelemarken), (PER, Christian Lofthuus)...   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...   \n",
       "116  [(PER, Camilla Collett), (PER, Collett), (ORG,...   \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...   \n",
       "118  [(PER, Sigurd), (PER, Begliot), (PER, Lina), (...   \n",
       "119  [(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...   \n",
       "\n",
       "                                           spacy_small  \n",
       "0                                                   []  \n",
       "1    [(ORG, Pigen Else Sophie Jensdatter Birkedalen...  \n",
       "2    [(LOC, Skrivelse), (PER, Opbrusning), (PER, Ov...  \n",
       "3    [(PER, Skrivelse), (PER, Catilinas), (PER, Mod...  \n",
       "4                               [(ORG, Homers Iliade)]  \n",
       "..                                                 ...  \n",
       "115  [(PER, Jernbane), (LOC, Neapel), (LOC, Castela...  \n",
       "116  [(PER, Camilla Collett), (PER, Livs), (LOC, Li...  \n",
       "117  [(ORG, Sigurd), (PER, Christian Krohg), (ORG, ...  \n",
       "118  [(ORG, Sigurd), (LOC, Bergliot), (PER, Lina), ...  \n",
       "119  [(ORG, 6te i Rækken), (LOC, Trondhjem), (ORG, ...  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\\")\n",
    "#path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\\") #misc version\n",
    "df_ss.to_csv(os.path.join(path,r'spacy_small_w_annotation.csv'), encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------ spacy medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253\n",
      "1596\n",
      "{'exact': {'count': 120,\n",
      "           'f1_score': 77.4688290302681,\n",
      "           'precision': 76.92124476504533,\n",
      "           'recall': 83.37729534841763},\n",
      " 'partial': {'count': 120,\n",
      "             'f1_score': 84.06329785152332,\n",
      "             'precision': 83.03524229624824,\n",
      "             'recall': 91.17329338947877},\n",
      " 'strict': {'count': 120,\n",
      "            'f1_score': 66.32804706552957,\n",
      "            'precision': 66.03480021777453,\n",
      "            'recall': 70.56760536971721},\n",
      " 'type': {'count': 120,\n",
      "          'f1_score': 73.68800035454751,\n",
      "          'precision': 73.01068062533767,\n",
      "          'recall': 78.78726287858623}}\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\brev_spacy_medium.csv', converters={'spacy_medium': literal_eval})\n",
    "\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\annotations\\\\done' # MISC Version\n",
    "#all_files = glob.glob(path + \"/*.csv\")\n",
    "#csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\brev_spacy_medium.csv', converters={'spacy_medium': literal_eval})\n",
    "\n",
    "\n",
    "ground_truths = []\n",
    "predictions = []\n",
    "file_names = []\n",
    "\n",
    "for filename in all_files:\n",
    "    brev_filename = filename\n",
    "    brev_filename = re.match(r'.*done\\\\(.*).csv', brev_filename)\n",
    "    brev_filename = brev_filename.group(1)\n",
    "   \n",
    "    for i,r in csv_df.iterrows():\n",
    "        files = r['files']\n",
    "        if files == brev_filename:\n",
    "            spacy_medium = r['spacy_medium']\n",
    "            predictions.append(spacy_medium)\n",
    "            f = r['files']\n",
    "            file_names.append(f)\n",
    "            \n",
    "    df = pd.read_csv(filename)\n",
    "    li_1 = []\n",
    "    \n",
    "    for i,r in df.iterrows():\n",
    "        annotation = r['human_annotation']\n",
    "        annotation = str(annotation)\n",
    "        annotation = annotation.split(\";\")\n",
    "        annotation = str(annotation)\n",
    "        annotation = re.sub(\"'\", '', annotation)\n",
    "        annotation = re.sub(\"\\[\", '', annotation)\n",
    "        annotation = re.sub(\"\\]\", '', annotation)\n",
    "        li_1.append(annotation)\n",
    "        end_list_a = []\n",
    "\n",
    "    for i in li_1:\n",
    "        if re.match(r'nan', i):\n",
    "            pass\n",
    "        else:\n",
    "            words = re.match(r'(\\()(\\w.*), {1} ?(:? ?\\w.* ?\\w*)(\\))', i)\n",
    "            elem_1 = words.group(2)\n",
    "            elem_2 = words.group(3)\n",
    "            full = (elem_1, elem_2)\n",
    "            end_list_a.append(full)\n",
    "                \n",
    "    ground_truths.append(end_list_a)\n",
    "    \n",
    "lists = {'filename': file_names, 'texts': texts, 'ground_truths': ground_truths, 'spacy_medium': predictions}\n",
    "\n",
    "df_sm = pd.DataFrame.from_dict(lists, orient = 'index')\n",
    "df_sm = df_sm.transpose()\n",
    "\n",
    "count = 0\n",
    "for e in ground_truths:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for e in predictions:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "ground_truths_r = ground_truths\n",
    "\n",
    "#spacy_medium_result = muc.evaluate_all(predictions, ground_truths_r * 1, texts, verbose=True)\n",
    "pprint.pprint(spacy_medium_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>texts</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>spacy_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREV_B1844-1871ht_B18450801AWE</td>\n",
       "      <td>Jomfru M: Wahl hilses venskabeligst fra</td>\n",
       "      <td>[(PER, M: Wahl)]</td>\n",
       "      <td>[(MISC, Jomfru M), (PER, Wahl)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREV_B1844-1871ht_B18461207JCP</td>\n",
       "      <td>Opfordret af Deres Velbaarenhed til at erklære...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen), (PE...</td>\n",
       "      <td>[(ORG, Deres Velbaarenhed), (PER, Else Sophie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREV_B1844-1871ht_B18491015OS</td>\n",
       "      <td>Dit sidste Brev har i dobbelt Henseende glædet...</td>\n",
       "      <td>[(PER, Due), (MISC, C.)]</td>\n",
       "      <td>[(ORG, Opbrusning og Overilelse), (LOC, Tilbli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREV_B1844-1871ht_B18500105OS</td>\n",
       "      <td>Gjennem din sidste Skrivelse har jeg modtaget ...</td>\n",
       "      <td>[(MISC, Catilinas), (MISC, C.), (MISC, Olaf T....</td>\n",
       "      <td>[(PER, Catilinas), (PER, C.), (MISC, Stykket),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREV_B1844-1871ht_B18500728AkKoll</td>\n",
       "      <td>Undertegnede opgiver herved at have læst 12te ...</td>\n",
       "      <td>[(MISC, Homers Iliade)]</td>\n",
       "      <td>[(PER, Homers Iliade), (LOC, Æqvivalent)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>BREV_B1890-1905ht_Budat1891JLi</td>\n",
       "      <td>Jernbane fra Neapel til Castelamare (omtr. 1¼ ...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18930116NN_Fest</td>\n",
       "      <td>De store Fortjenester, Fru Camilla Collett har...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Collett), (ORG,...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Livs), (MISC, L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18950427SuI</td>\n",
       "      <td>Dit brev af 18de fik jeg her den 23de; men jeg...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189504SuI</td>\n",
       "      <td>Jeg skriver idag bare nogle få ord for at du k...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Begliot), (PER, Lina), (...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum</td>\n",
       "      <td>Et Tidsrum af 12 Aar er forløbet, siden den si...</td>\n",
       "      <td>[(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...</td>\n",
       "      <td>[(LOC, Trondhjem), (ORG, Opmerksomhed), (PER, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename  \\\n",
       "0                BREV_B1844-1871ht_B18450801AWE   \n",
       "1                BREV_B1844-1871ht_B18461207JCP   \n",
       "2                 BREV_B1844-1871ht_B18491015OS   \n",
       "3                 BREV_B1844-1871ht_B18500105OS   \n",
       "4             BREV_B1844-1871ht_B18500728AkKoll   \n",
       "..                                          ...   \n",
       "115              BREV_B1890-1905ht_Budat1891JLi   \n",
       "116      BREV_B1890-1905ht_Budat18930116NN_Fest   \n",
       "117          BREV_B1890-1905ht_Budat18950427SuI   \n",
       "118            BREV_B1890-1905ht_Budat189504SuI   \n",
       "119  BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum   \n",
       "\n",
       "                                                 texts  \\\n",
       "0              Jomfru M: Wahl hilses venskabeligst fra   \n",
       "1    Opfordret af Deres Velbaarenhed til at erklære...   \n",
       "2    Dit sidste Brev har i dobbelt Henseende glædet...   \n",
       "3    Gjennem din sidste Skrivelse har jeg modtaget ...   \n",
       "4    Undertegnede opgiver herved at have læst 12te ...   \n",
       "..                                                 ...   \n",
       "115  Jernbane fra Neapel til Castelamare (omtr. 1¼ ...   \n",
       "116  De store Fortjenester, Fru Camilla Collett har...   \n",
       "117  Dit brev af 18de fik jeg her den 23de; men jeg...   \n",
       "118  Jeg skriver idag bare nogle få ord for at du k...   \n",
       "119  Et Tidsrum af 12 Aar er forløbet, siden den si...   \n",
       "\n",
       "                                         ground_truths  \\\n",
       "0                                     [(PER, M: Wahl)]   \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen), (PE...   \n",
       "2                             [(PER, Due), (MISC, C.)]   \n",
       "3    [(MISC, Catilinas), (MISC, C.), (MISC, Olaf T....   \n",
       "4                              [(MISC, Homers Iliade)]   \n",
       "..                                                 ...   \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...   \n",
       "116  [(PER, Camilla Collett), (PER, Collett), (ORG,...   \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...   \n",
       "118  [(PER, Sigurd), (PER, Begliot), (PER, Lina), (...   \n",
       "119  [(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...   \n",
       "\n",
       "                                          spacy_medium  \n",
       "0                      [(MISC, Jomfru M), (PER, Wahl)]  \n",
       "1    [(ORG, Deres Velbaarenhed), (PER, Else Sophie ...  \n",
       "2    [(ORG, Opbrusning og Overilelse), (LOC, Tilbli...  \n",
       "3    [(PER, Catilinas), (PER, C.), (MISC, Stykket),...  \n",
       "4            [(PER, Homers Iliade), (LOC, Æqvivalent)]  \n",
       "..                                                 ...  \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...  \n",
       "116  [(PER, Camilla Collett), (PER, Livs), (MISC, L...  \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...  \n",
       "118  [(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...  \n",
       "119  [(LOC, Trondhjem), (ORG, Opmerksomhed), (PER, ...  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\\")\n",
    "#path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\\") #misc version\n",
    "df_sm.to_csv(os.path.join(path,r'spacy_medium_w_annotation.csv'), encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------- spacy large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253\n",
      "1544\n",
      "{'exact': {'count': 120,\n",
      "           'f1_score': 77.02853640311709,\n",
      "           'precision': 76.49057387390623,\n",
      "           'recall': 82.22554978388382},\n",
      " 'partial': {'count': 120,\n",
      "             'f1_score': 85.26854086950648,\n",
      "             'precision': 84.8130619057062,\n",
      "             'recall': 91.1152469445729},\n",
      " 'strict': {'count': 120,\n",
      "            'f1_score': 65.79907932971321,\n",
      "            'precision': 64.8637240559305,\n",
      "            'recall': 70.47558012071724},\n",
      " 'type': {'count': 120,\n",
      "          'f1_score': 74.90853472001278,\n",
      "          'precision': 73.86777364240194,\n",
      "          'recall': 80.15915081378377}}\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\annotations\\\\done' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\brev_spacy_large.csv', converters={'spacy_large': literal_eval})\n",
    "\n",
    "#path = r'C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\annotations\\\\done' # MISC Version\n",
    "#all_files = glob.glob(path + \"/*.csv\")\n",
    "#csv_df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\brev_spacy_large.csv', converters={'spacy_large': literal_eval})\n",
    "\n",
    "\n",
    "ground_truths = []\n",
    "predictions = []\n",
    "file_names = []\n",
    "\n",
    "for filename in all_files:\n",
    "    brev_filename = filename\n",
    "    brev_filename = re.match(r'.*done\\\\(.*).csv', brev_filename)\n",
    "    brev_filename = brev_filename.group(1)\n",
    "  \n",
    "    for i,r in csv_df.iterrows():\n",
    "        files = r['files']\n",
    "        if files == brev_filename:\n",
    "            spacy_large = r['spacy_large']\n",
    "            predictions.append(spacy_large)\n",
    "            f = r['files']\n",
    "            file_names.append(f)\n",
    "            \n",
    "    df = pd.read_csv(filename)    \n",
    "    li_1 = []\n",
    "\n",
    "    for i,r in df.iterrows():\n",
    "        annotation = r['human_annotation']\n",
    "        annotation = str(annotation)\n",
    "        annotation = annotation.split(\";\")\n",
    "        annotation = str(annotation)\n",
    "        annotation = re.sub(\"'\", '', annotation)\n",
    "        annotation = re.sub(\"\\[\", '', annotation)\n",
    "        annotation = re.sub(\"\\]\", '', annotation)\n",
    "        li_1.append(annotation)\n",
    "        end_list_a = []\n",
    "\n",
    "    for i in li_1:\n",
    "        if re.match(r'nan', i):\n",
    "            pass\n",
    "        else:\n",
    "            words = re.match(r'(\\()(\\w.*), {1} ?(:? ?\\w.* ?\\w*)(\\))', i)\n",
    "            elem_1 = words.group(2)\n",
    "            elem_2 = words.group(3)\n",
    "            full = (elem_1, elem_2)\n",
    "            end_list_a.append(full)\n",
    "                \n",
    "    ground_truths.append(end_list_a)\n",
    "    \n",
    "lists = {'filename': file_names, 'texts': texts, 'ground_truths': ground_truths, 'spacy_large': predictions}\n",
    "\n",
    "df_sl = pd.DataFrame.from_dict(lists, orient = 'index')\n",
    "df_sl = df_sl.transpose()\n",
    "\n",
    "count = 0\n",
    "for e in ground_truths:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for e in predictions:\n",
    "    count += len(e) \n",
    "print(count)\n",
    "\n",
    "ground_truths_r = ground_truths\n",
    "\n",
    "#spacy_large_result = muc.evaluate_all(predictions, ground_truths_r * 1, texts, verbose=True)\n",
    "pprint.pprint(spacy_large_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\csv\\\\\")\n",
    "#path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work_misc\\\\csv\\\\\") #misc version\n",
    "df_sl.to_csv(os.path.join(path,r'spacy_large_w_annotation.csv'), encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>texts</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>spacy_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREV_B1844-1871ht_B18450801AWE</td>\n",
       "      <td>Jomfru M: Wahl hilses venskabeligst fra</td>\n",
       "      <td>[(PER, M: Wahl)]</td>\n",
       "      <td>[(ORG, Jomfru M), (PER, Wahl)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREV_B1844-1871ht_B18461207JCP</td>\n",
       "      <td>Opfordret af Deres Velbaarenhed til at erklære...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen), (PE...</td>\n",
       "      <td>[(PER, Else Sophie Jensdatter Birkedalen), (PE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREV_B1844-1871ht_B18491015OS</td>\n",
       "      <td>Dit sidste Brev har i dobbelt Henseende glædet...</td>\n",
       "      <td>[(PER, Due)]</td>\n",
       "      <td>[(PER, Opfatningsmaade), (PER, Synspunct), (PE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREV_B1844-1871ht_B18500105OS</td>\n",
       "      <td>Gjennem din sidste Skrivelse har jeg modtaget ...</td>\n",
       "      <td>[(LOC, Thelemarken), (PER, Christian Lofthuus)...</td>\n",
       "      <td>[(PER, Modet), (PER, C.), (ORG, Stykkets Afvii...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREV_B1844-1871ht_B18500728AkKoll</td>\n",
       "      <td>Undertegnede opgiver herved at have læst 12te ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(ORG, Æqvivalent)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>BREV_B1890-1905ht_Budat1891JLi</td>\n",
       "      <td>Jernbane fra Neapel til Castelamare (omtr. 1¼ ...</td>\n",
       "      <td>[(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...</td>\n",
       "      <td>[(LOC, Neapel), (ORG, Castelamare), (LOC, Viet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18930116NN_Fest</td>\n",
       "      <td>De store Fortjenester, Fru Camilla Collett har...</td>\n",
       "      <td>[(PER, Camilla Collett), (PER, Collett), (ORG,...</td>\n",
       "      <td>[(PER, Fru Camilla Collett), (ORG, Medborgerin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>BREV_B1890-1905ht_Budat18950427SuI</td>\n",
       "      <td>Dit brev af 18de fik jeg her den 23de; men jeg...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189504SuI</td>\n",
       "      <td>Jeg skriver idag bare nogle få ord for at du k...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Begliot), (PER, Lina), (...</td>\n",
       "      <td>[(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum</td>\n",
       "      <td>Et Tidsrum af 12 Aar er forløbet, siden den si...</td>\n",
       "      <td>[(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...</td>\n",
       "      <td>[(PER, Sangerfest), (LOC, Trondhjem), (PER, Sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename  \\\n",
       "0                BREV_B1844-1871ht_B18450801AWE   \n",
       "1                BREV_B1844-1871ht_B18461207JCP   \n",
       "2                 BREV_B1844-1871ht_B18491015OS   \n",
       "3                 BREV_B1844-1871ht_B18500105OS   \n",
       "4             BREV_B1844-1871ht_B18500728AkKoll   \n",
       "..                                          ...   \n",
       "115              BREV_B1890-1905ht_Budat1891JLi   \n",
       "116      BREV_B1890-1905ht_Budat18930116NN_Fest   \n",
       "117          BREV_B1890-1905ht_Budat18950427SuI   \n",
       "118            BREV_B1890-1905ht_Budat189504SuI   \n",
       "119  BREV_B1890-1905ht_Budat189509NN_Et_Tidsrum   \n",
       "\n",
       "                                                 texts  \\\n",
       "0              Jomfru M: Wahl hilses venskabeligst fra   \n",
       "1    Opfordret af Deres Velbaarenhed til at erklære...   \n",
       "2    Dit sidste Brev har i dobbelt Henseende glædet...   \n",
       "3    Gjennem din sidste Skrivelse har jeg modtaget ...   \n",
       "4    Undertegnede opgiver herved at have læst 12te ...   \n",
       "..                                                 ...   \n",
       "115  Jernbane fra Neapel til Castelamare (omtr. 1¼ ...   \n",
       "116  De store Fortjenester, Fru Camilla Collett har...   \n",
       "117  Dit brev af 18de fik jeg her den 23de; men jeg...   \n",
       "118  Jeg skriver idag bare nogle få ord for at du k...   \n",
       "119  Et Tidsrum af 12 Aar er forløbet, siden den si...   \n",
       "\n",
       "                                         ground_truths  \\\n",
       "0                                     [(PER, M: Wahl)]   \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen), (PE...   \n",
       "2                                         [(PER, Due)]   \n",
       "3    [(LOC, Thelemarken), (PER, Christian Lofthuus)...   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "115  [(LOC, Neapel), (LOC, Castelamare), (LOC, Viet...   \n",
       "116  [(PER, Camilla Collett), (PER, Collett), (ORG,...   \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...   \n",
       "118  [(PER, Sigurd), (PER, Begliot), (PER, Lina), (...   \n",
       "119  [(LOC, Trondhjem), (LOC, Kristiania), (LOC, Kr...   \n",
       "\n",
       "                                           spacy_large  \n",
       "0                       [(ORG, Jomfru M), (PER, Wahl)]  \n",
       "1    [(PER, Else Sophie Jensdatter Birkedalen), (PE...  \n",
       "2    [(PER, Opfatningsmaade), (PER, Synspunct), (PE...  \n",
       "3    [(PER, Modet), (PER, C.), (ORG, Stykkets Afvii...  \n",
       "4                                  [(ORG, Æqvivalent)]  \n",
       "..                                                 ...  \n",
       "115  [(LOC, Neapel), (ORG, Castelamare), (LOC, Viet...  \n",
       "116  [(PER, Fru Camilla Collett), (ORG, Medborgerin...  \n",
       "117  [(PER, Sigurd), (PER, Bergliot), (PER, Sigurds...  \n",
       "118  [(PER, Sigurd), (PER, Bergliot), (PER, Lina), ...  \n",
       "119  [(PER, Sangerfest), (LOC, Trondhjem), (PER, Sa...  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truths)  # 120 files are annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for e in ground_truths:\n",
    "    count += len(e) \n",
    "    \n",
    "count   # there are 1253 human annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1544"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for e in predictions:\n",
    "    count += len(e) \n",
    "count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact': {'count': 120,\n",
      "           'f1_score': 81.67493674885893,\n",
      "           'precision': 80.73000403735635,\n",
      "           'recall': 85.37988352316434},\n",
      " 'partial': {'count': 120,\n",
      "             'f1_score': 88.20620165839706,\n",
      "             'precision': 87.29999603081625,\n",
      "             'recall': 92.33109916191884},\n",
      " 'strict': {'count': 120,\n",
      "            'f1_score': 73.79964760635819,\n",
      "            'precision': 72.53993216016502,\n",
      "            'recall': 77.45966728890633},\n",
      " 'type': {'count': 120,\n",
      "          'f1_score': 84.51481479373949,\n",
      "          'precision': 83.23265193557788,\n",
      "          'recall': 88.8092486114581}}\n"
     ]
    }
   ],
   "source": [
    "#dacy_m_result = muc.evaluate_all(predictions, ground_truths * 1, texts, verbose=True)\n",
    "pprint.pprint(dacy_m_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dacy_small_result = muc.evaluate_all(predictions, ground_truths * 1, texts, verbose=True)\n",
    "pprint.pprint(dacy_small_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dacy_l_result = muc.evaluate_all(predictions, ground_truths * 1, texts, verbose=True)\n",
    "pprint.pprint(dacy_l_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy_trf_result = muc.evaluate_all(predictions, ground_truths * 1, texts, verbose=True)\n",
    "pprint.pprint(spacy_trf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy_large_result = muc.evaluate_all(predictions, ground_truths * 1, texts, verbose=True)\n",
    "pprint.pprint(spacy_large_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy_medium_result = muc.evaluate_all(predictions, ground_truths * 1, texts, verbose=True)\n",
    "pprint.pprint(spacy_medium_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy_small_result = muc.evaluate_all(predictions, ground_truths * 1, texts, verbose=True)\n",
    "pprint.pprint(spacy_small_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
